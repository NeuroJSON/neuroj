#!/usr/bin/perl
###############################################################################
#
# NeuroJSON client (neuroj)
#
# Author:  Qianqian Fang <q.fang at neu.edu>
# License: BSD-3-clause
# Version: 0.5
# Github:  https://github.com/NeuroJSON/neuroj
#
###############################################################################
#
# Dependencies:
#
# For Linux and Mac OS: 
#   jq, curl, octave, jbids (https://github.com/NeuroJSON/jbids - including 4
#   submodules under tools), libparallel-forkmanager-perl (for Parallel::ForkManager)
#   libwww-perl (for LWP::UserAgent), libjson-xs-perl (for JSON::XS)
#
# For Windows: please install cygwin64 (http://cygwin.com/) or MSYS2 (http://msys2.org/)
#   please also install jq, curl, octave, jbids (https://github.com/NeuroJSON/jbids)
#
# Specifically, this script requires Perl 5.x and curl (if curl is not install 
# in the path, it looks for the LWP::UserAgent perl modules).
#
# When using --convert, conversion for some of the data files, such as .snirf or
# .nii/.nii.gz requires octave and the jbids toolbox (including its submodules).
# Other functionalities does not require octave.
#
# How to use:
#    type "neuroj --help" to see the format
#
# Examples:
#   # print help information and flags
#   neuroj
#
#   # preview commands (dry-run, does not execute) to convert a database (including all included datasets) to JSON
#   neuroj -i /path/to/database/rootfolder -o /path/to/output/json/folder -db openneuro
#
#   # convert a database (a collection of datasets) to JSON in batch with 12 parallel threads (1 thread per dataset)
#   neuroj -i /path/to/database/rootfolder -o /path/to/output/json/folder -db openneuro --convert -t 12
#
#   # convert a single dataset (including all files under sub-folders) to JSON in parallel (1 thread per file)
#   neuroj -i /path/to/database/rootfolder -o /path/to/output/json/folder -db openneuro -ds ds000001 --convert
#
#   # convert a database to JSON, assuming the last segment of the input path as database name
#   neuroj -i /path/to/database/databasename -o /path/to/output/json/folder
#
#   # convert a single dataset ds000001 to JSON (dry-run only, add --convert to run)
#   neuroj -i /path/to/database/databasename -o /path/to/output/json/folder -ds ds000001
#
#   # list all databases currently hosted on NeuroJSON.io
#   neuroj --list
#
#   # list all datasets strored under the "openneuro" database
#   neuroj --list -db openneuro
#
#   # list all datasets strored under the "openneuro" database and print all datasets using jq filters
#   neuroj --list -db openneuro | jq '.rows[] | .id'
#
#   # query server-level information of the database openneuro (return dataset count, file sizes etc)
#   neuroj --info -db openneuro
#
#   # search the IDs of the first 10 (limit:10) datasets in the openneuro database starting from the 3rd (skip:2) datasets
#   neuroj -db openneuro --find '{"selector":{},"fields":["_id"],"limit":10,"skip":2}'
#
#   # query the dataset name "_id" and "dataset_description.json" records of the first two datasets in "openneuro" and format with jq
#   neuroj -db openneuro --find '{"selector":{},"fields":["_id","bids_dataset_info.dataset_description\\.json"],"limit":2}' | jq '.'
#
###############################################################################

use File::Find;
use strict;
use warnings;
no warnings 'uninitialized';

if(@ARGV==0 || grep(/--help/,@ARGV)){
    &printhelp;
}

my ($infolder, $outfolder, $dbname, $dsname, $threads);
my %action=();
my $serverurl="https://neurojson.io:7777";

$threads=4;

while(my $opt = $ARGV[0]) {
    if($opt =~ /^-[-a-zA-Z]/){
        if($opt eq '-i' || $opt eq '--input'){
                shift;
                $infolder=shift;
                $infolder=~s/\/$//g;
        }elsif($opt eq '-o' || $opt eq '--output'){
                shift;
                $outfolder=shift;
                $outfolder=~s/\/$//g;
        }elsif($opt eq '-db' || $opt eq '--database'){
                shift;
                $dbname=shift;
        }elsif($opt eq '-ds' || $opt eq '--dataset'){
                shift;
                $dsname=shift;
        }elsif($opt eq '-c' || $opt eq '--couchdb'){
                shift;
                $serverurl=shift;
        }elsif($opt eq '-t' || $opt eq '--threads'){
                shift;
                $threads=shift;
        }elsif($opt eq '-l' || $opt eq '--list'){
                shift;
                $action{"list"}=1;
        }elsif($opt eq '-q' || $opt eq '--info'){
                shift;
                $action{"info"}=1;
        }elsif($opt eq '-j' || $opt eq '--tojson'){
                shift;
                $action{"tojson"}=1;
        }elsif($opt eq '-f' || $opt eq '--find'){
                shift;
                $action{"find"}=shift;
        }elsif($opt eq '-d' || $opt eq '--download'){
                shift;
                $action{"download"}=1;
        }elsif($opt eq '-r' || $opt eq '--convert'){
                shift;
                $action{"convert"}=1;
        }
    }
}

if($infolder ne '' && $outfolder ne '') {
    convert($infolder, $outfolder, $dbname, $dsname, $action{"convert"});
}

if(exists($action{"info"})) {
    my $url =($dbname ne '') ? (($dsname ne '') ? "$serverurl/$dbname/$dsname" : "$serverurl/$dbname") : "$serverurl/_dbs_info";

    my $content='';
    if($dsname ne '') {
        $content=`curl -s --head "$url"`;
        my @lines=grep {! /^\s*$/} split("\n", $content);
        $content="{\n";
        for(my $i=0; $i<=$#lines; $i++) {
            if($lines[$i] =~ /^([^:]+)\s*:\s*([^\r\n]+)/) {
                my ($headkey, $headval)=($1, $2);
                $headval="\"$2\"" if $headval !~ /^"|^\d+$/;
                $content .= "\t\"$headkey\" : $headval".(($i==$#lines) ? "\n" : ",\n");
            }
        }
        $content .="}\n";
    } else {
        $content=webget($url);
    }
    if($content ne ''){
          print $content;
    }
}

if(exists($action{"list"})) {
    my $url =($dbname ne '') ? "$serverurl/$dbname/_all_docs" : "$serverurl/_dbs_info";

    my $content=webget($url);
    if($content ne ''){
          print $content;
    }
}

if(exists($action{"download"}) && $dbname ne '') {
    my $url=($dsname ne '') ? "$serverurl/$dbname/$dsname" : "$serverurl/$dbname/";
    my $content=webget($url);

    if($content ne ''){
          print $content;
    }
}

if(exists($action{"find"}) && $dbname ne '') {
    my $url ="$serverurl/$dbname/_find";
    my $content=webpost($url, $action{'find'});
    if($content ne ''){
          print $content;
    }
}

sub webget {
    my ($url)=@_;

    my $content=`curl -s -X GET "$url"`;
    if($content eq ''){
           eval("use LWP::UserAgent (); 1")  or warn "LWP::UserAgent is not available: $@";;
           my $ua      = LWP::UserAgent->new();
           my $response = $ua->get($url);
           $content = $response->decoded_content;
     }
     return $content;
}

sub webpost {
    my ($url, $formjson)=@_;

    my $content=`curl -s --header 'Content-Type: application/json' -X POST -d '$formjson' '$url'`;
    if($content eq ''){
           eval("use LWP::UserAgent (); 1")  or warn "LWP::UserAgent is not available: $@";;
           my $ua      = LWP::UserAgent->new();
           my $json = JSON::PP->new;
           my %form=$json->encode($formjson);
           my $response = $ua->post($url, \%form);
           $content = $response->decoded_content;
     }
     return $content;
}

sub convert {
    my ($inputroot, $outputroot, $dbname, $dsname, $doconvert)=@_;
    my $hasparallel=1;
    my $manager;
    my @datasets=();
    if($dsname ne '') {
        find({ wanted => sub { push(@datasets, $_) if $_ !~ /\/\.[^\/]+$/ }, no_chdir => 1}, "$inputroot/$dsname");
    } else {
        @datasets=glob("$inputroot/*/");
    }

    my @args=($inputroot, $outputroot);
    if($dbname ne '') {
        push(@args, $dbname);
    } else {
        if($inputroot =~ /([^\/]+)\/*$/) {
            push(@args, $1);
        } else {
            push(@args, "");
        }
    }
    push(@args, $dsname);
    push(@args, "") if($dbname ne ''); # args[4] sets file name

    # dynamically test if parallel::forkmanager module is available, if not, fall back to serial
    eval("use Parallel::ForkManager; 1")  or do {
       warn "Parallel::ForkManager is not available: $@";
       $hasparallel=0;
    };

    $manager = Parallel::ForkManager->new($threads) if($hasparallel);

    foreach my $ds (@datasets) {
        if($hasparallel) {
            $manager->start and next;
        }
        if($dsname ne '') {
            $args[4]=$ds;
        } elsif ($ds =~ /([^\/]+)\/*$/) {
            $args[3]=$1;
        }
        if ($doconvert==1) {
            system("njprep",@args);
        } else {
            print "njprep\t".join("\t", @args)."\n"; # preview of the commands
        }
        $manager->finish if $hasparallel;
    }
    $manager->wait_all_children if $hasparallel;

    if($doconvert==1 && $dsname ne '') {
        system("mergejson", "$outputroot/${dsname}");   # merge subject-folder json files to a single .jbids file
    }
}

sub printhelp{
    printf("Format: %s <param1> <param2> ...

Suported flags include

  -i/--input folderpath   path to the top folder of a data collection (such as OpenNeuro)
  -o/--output folderpath  path to the output folder storing the converted JSON files
  -db/--database dbname   database name (such as openneuro, openfnirs, dandi etc)
  -ds/--dataset dataset   dataset name (a single dataset in a collection, such as ds00001)
  -r/--convert            convert database (-db) or dataset (-db .. -ds ..) (in parallel) to JSON
  -t/--threads num        set the thread number for parallel conversion (4 by default)
  -c/--couchdb url        set the CouchDB REST API root url, use https://neurojson.io:7777 by default
  -l/--list               list all database if -db is given; or the dataset if both -db/-ds are given
  -q/--info               query database info if -db is given; or dataset info if both -db/-ds are given
  -f/--find '{\"selector\":,...}' use the CouchDB _find API to search dataset
  -d/--download           retrieve and display JSON encoded dataset, or complete database (slow)
",  $0);
    exit 0;
}
      
exit(0);
1
